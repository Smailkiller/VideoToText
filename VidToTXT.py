import os
import wave
import json
import sys
from vosk import Model, KaldiRecognizer
from pydub import AudioSegment

# ==========================
# üîß –ü–ê–†–ê–ú–ï–¢–†–´ –î–õ–Ø –ù–ê–°–¢–†–û–ô–ö–ò
# ==========================
video_root_path = r"path1"                     # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞–º–∏ (–≤–æ–∑–º–æ–∂–Ω–æ —Å –ø–æ–¥–ø–∞–ø–∫–∞–º–∏)
vosk_model_path = r"path2"                     # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ Vosk
# ==========================

def extract_audio(video_path, wav_path):
    audio = AudioSegment.from_file(video_path)
    audio = audio.set_channels(1)
    audio = audio.set_frame_rate(16000)
    audio.export(wav_path, format="wav", parameters=["-acodec", "pcm_s16le"])

def transcribe_audio(wav_path, model):
    wf = wave.open(wav_path, "rb")
    rec = KaldiRecognizer(model, wf.getframerate())
    rec.SetWords(True)

    total = wf.getnframes()
    read = 0
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        rec.AcceptWaveform(data)
        read += 4000
        percent = min(100, int(read / total * 100))
        print(f"\r    üü© –ü—Ä–æ–≥—Ä–µ—Å—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {percent}%", end="")
        sys.stdout.flush()
    print("\n    ‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    return json.loads(rec.FinalResult()).get("text", "")

def process_videos(base_folder, model_path):
    print(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Vosk –∏–∑: {model_path}")
    model = Model(model_path)

    video_files = []
    for root, _, files in os.walk(base_folder):
        for f in files:
            video_files.append(os.path.join(root, f))

    print(f"üîé –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤: {len(video_files)}\n")

    error_log_path = os.path.join(base_folder, "error_log.txt")
    if os.path.exists(error_log_path):
        os.remove(error_log_path)

    supported_ext = (".mp4", ".mov", ".mkv", ".avi", ".webm", ".mpeg", ".mpg")

    for idx, video_path in enumerate(video_files, 1):
        if not video_path.lower().endswith(supported_ext):
            continue

        print(f"üîÑ [{idx}/{len(video_files)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {video_path}")
        base_name = os.path.splitext(video_path)[0]
        wav_path = base_name + ".wav"
        txt_path = base_name + ".txt"

        try:
            print("    üéß –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ...")
            extract_audio(video_path, wav_path)
        except Exception as e:
            print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e}")
            with open(error_log_path, "a", encoding="utf-8") as log_f:
                log_f.write(f"[Audio Extract Error] {video_path}: {e}\n")
            continue

        try:
            print("    üñãÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è...")
            text = transcribe_audio(wav_path, model)

            video_filename = os.path.basename(base_name)
            with wave.open(wav_path, "rb") as wf:
                duration = round(wf.getnframes() / wf.getframerate(), 1)

            with open(txt_path, "w", encoding="utf-8") as f:
                f.write(f"# {video_filename} | –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration} —Å–µ–∫\n")
                f.write(text)

            print(f"    üìè –ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω—ë–Ω —Ç–µ–∫—Å—Ç: {txt_path}\n")

        except Exception as e:
            print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
            with open(error_log_path, "a", encoding="utf-8") as log_f:
                log_f.write(f"[Transcription Error] {video_path}: {e}\n")
            continue

    print("‚úÖ –í—Å–µ –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")

if __name__ == "__main__":
    process_videos(video_root_path, vosk_model_path)
